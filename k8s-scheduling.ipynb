{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9d550-822c-4ebf-bea2-55b5740d62dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, uuid, time, csv, os\n",
    "\n",
    "from kubernetes import client, config, watch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "config.load_kube_config(\"/home/goughes/k8s/configs/erikdev-admin.yaml\")\n",
    "core_api = client.CoreV1Api()\n",
    "batch_api = client.BatchV1Api()\n",
    "apps_api = client.AppsV1Api()\n",
    "# create results directory structure\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "experiments = [\"E1\", \"E2\", \"E3\", \"E4\", \"E5\"]\n",
    "for e in experiments:\n",
    "    os.makedirs(\"results/\" + e, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75ce30-7052-4bdd-a049-ac5d53479426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90734756-7a6b-4d8b-b0e4-4a9faece7fd6",
   "metadata": {},
   "source": [
    "## Kubernetes API class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ec392-3cac-4d22-aed2-9744e3d8c61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on https://medium.com/@aris.david/how-to-create-a-job-using-kubernetes-python-client-ed00ac2b791d\n",
    "class Kubernetes:\n",
    "    def __init__(self):\n",
    "\n",
    "        # Init Kubernetes\n",
    "        self.core_api = client.CoreV1Api()\n",
    "        self.batch_api = client.BatchV1Api()\n",
    "\n",
    "    def get_all_namespaces(self):\n",
    "        namespaces = self.core_api.list_namespace()\n",
    "        all_namespaces = []\n",
    "        for ns in namespaces.items:\n",
    "            all_namespaces.append(ns.metadata.name)\n",
    "        return all_namespaces\n",
    "            \n",
    "    def create_namespace(self, namespace):\n",
    "\n",
    "        all_namespaces = self.get_all_namespaces()\n",
    "\n",
    "        if namespace in all_namespaces:\n",
    "            logging.info(f\"Namespace {namespace} already exists. Reusing.\")\n",
    "        else:\n",
    "            namespace_metadata = client.V1ObjectMeta(name=namespace)\n",
    "            self.core_api.create_namespace(\n",
    "                client.V1Namespace(metadata=namespace_metadata)\n",
    "            )\n",
    "            logging.info(f\"Created namespace {namespace}.\")\n",
    "\n",
    "        return namespace\n",
    "    \n",
    "    def delete_namespace(self, namespace):\n",
    "        all_namespaces = self.get_all_namespaces()\n",
    "        \n",
    "        if namespace not in all_namespaces:\n",
    "            logging.info(f\"Namespace {namespace} does not exist.\")\n",
    "        else:\n",
    "            self.core_api.delete_namespace(name=namespace)\n",
    "            logging.info(f\"Deleted namespace {namespace}.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def create_container(image, name, pull_policy, cpu_limit, mem_limit, sleep_time):\n",
    "\n",
    "        resources = client.V1ResourceRequirements(\n",
    "            requests={\"cpu\": cpu_limit, \"memory\": mem_limit},\n",
    "            limits={\"cpu\": cpu_limit, \"memory\": mem_limit}\n",
    "        )\n",
    "            \n",
    "        container = client.V1Container(\n",
    "            image=image,\n",
    "            name=name,\n",
    "            resources=resources,\n",
    "            image_pull_policy=pull_policy,\n",
    "            args=[sleep_time],\n",
    "            command=[\"sleep\"],\n",
    "        )\n",
    "\n",
    "        logging.info(\n",
    "            f\"Created sleep container with name: {container.name}, \"\n",
    "            f\"image: {container.image} and args: {container.args}\"\n",
    "        )\n",
    "\n",
    "        return container\n",
    "\n",
    "    @staticmethod\n",
    "    def create_pod_template(namespace, pod_name, container, scheduler_name):\n",
    "        labels={\"pod_name\": pod_name}\n",
    "        # add queue and appid labels required for yunikorn \n",
    "        if scheduler_name == \"yunikorn\":\n",
    "            labels[\"applicationId\"] = pod_name.split(\"-\")[-1]\n",
    "            labels[\"queue\"] = \"root.tenants.\" + namespace\n",
    "        if namespace == \"backfill\":\n",
    "            pod_template = client.V1PodTemplateSpec(\n",
    "                spec=client.V1PodSpec(restart_policy=\"Never\", containers=[container], scheduler_name=scheduler_name, priority_class_name=\"backfill\"),\n",
    "                metadata=client.V1ObjectMeta(name=pod_name, labels=labels),\n",
    "            )\n",
    "        else:\n",
    "            pod_template = client.V1PodTemplateSpec(\n",
    "                spec=client.V1PodSpec(restart_policy=\"Never\", containers=[container], scheduler_name=scheduler_name),\n",
    "                metadata=client.V1ObjectMeta(name=pod_name, labels=labels),\n",
    "            )\n",
    "\n",
    "        return pod_template\n",
    "\n",
    "    @staticmethod\n",
    "    def create_job(job_name, pod_template):\n",
    "        metadata = client.V1ObjectMeta(name=job_name, labels={\"job_name\": job_name})\n",
    "\n",
    "        job = client.V1Job(\n",
    "            api_version=\"batch/v1\",\n",
    "            kind=\"Job\",\n",
    "            metadata=metadata,\n",
    "            #spec=client.V1JobSpec(backoff_limit=6, template=pod_template),\n",
    "            spec=client.V1JobSpec(template=pod_template),\n",
    "        )\n",
    "\n",
    "        return job\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_all_pods(namespace):\n",
    "        pods = core_api.list_namespaced_pod(namespace, pretty=True, timeout_seconds=60)\n",
    "        print(\"number of pods: \" + str(len(pods.items)))\n",
    "        return pods\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_all_jobs(namespace):\n",
    "        jobs = batch_api.list_namespaced_job(namespace, pretty=True, timeout_seconds=60)\n",
    "        print(\"number of jobs: \" + str(len(jobs.items)))\n",
    "        return jobs\n",
    "    \n",
    "    @staticmethod\n",
    "    def delete_all_jobs(namespace):\n",
    "        jobs = batch_api.list_namespaced_job(namespace, pretty=True, timeout_seconds=60)\n",
    "        deleteoptions = client.V1DeleteOptions()\n",
    "        for job in jobs.items:\n",
    "            print(\"Deleting job \" + job.metadata.name)\n",
    "            jobname = job.metadata.name\n",
    "            api_response = batch_api.delete_namespaced_job(jobname,\n",
    "                                                           namespace,\n",
    "                                                           grace_period_seconds=0, \n",
    "                                                           propagation_policy='Background')\n",
    "            logging.debug(api_response)\n",
    "    \n",
    "    \"\"\"\n",
    "        interval: time to wait/sleep between each job submission\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def submit_burst(namespace, scheduler_name, cpu_limit, mem_limit, total_jobs, sleep_time):\n",
    "        try:\n",
    "            image = \"busybox:1.36\"\n",
    "            container_name = \"burst-sleep-\" + namespace\n",
    "            pull_policy = \"Never\"\n",
    "            print(\"bursting\", total_jobs, \"sleep\", sleep_time)\n",
    "            burst_submitted = 0\n",
    "            while burst_submitted < total_jobs:\n",
    "                container = k8s.create_container(image, container_name, pull_policy, cpu_limit, mem_limit, sleep_time)\n",
    "\n",
    "                pod_id = uuid.uuid4()\n",
    "                job_id = pod_id\n",
    "                # create template\n",
    "                _pod_name = f\"{namespace}-burst-pod-{pod_id}\"\n",
    "                if namespace == \"backfill\":\n",
    "                        _pod_name = \"tenant-\" + _pod_name\n",
    "                _pod_spec = k8s.create_pod_template(namespace, _pod_name, container, scheduler_name)\n",
    "\n",
    "                # create job\n",
    "                _job_name = f\"{namespace}-burst-{job_id}\"\n",
    "                if namespace == \"backfill\":\n",
    "                        _job_name = \"tenant-\" + _job_name\n",
    "                _job = k8s.create_job(_job_name, _pod_spec)\n",
    "\n",
    "                # execute job\n",
    "                batch_api = client.BatchV1Api()\n",
    "                batch_api.create_namespaced_job(namespace, _job)\n",
    "                burst_submitted = burst_submitted + 1\n",
    "                print(\"burst jobs\", burst_submitted)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    @staticmethod\n",
    "    def submit_workflow(namespace, scheduler_name, cpu_limit, mem_limit, total_jobs, sleep_time, bursts, interval, experiment):\n",
    "        try:\n",
    "            image = \"busybox:1.36\"\n",
    "            container_name = \"sleep-\" + namespace\n",
    "            pull_policy = \"Never\"\n",
    "            execution_time = 0\n",
    "            jobs_submitted = 0\n",
    "            # some logic to delay the start of tenant3 jobs\n",
    "            if namespace == \"tenant3\":\n",
    "                time.sleep(60)\n",
    "                execution_time = 60\n",
    "                if experiment == \"E5\":\n",
    "                    time.sleep(30)\n",
    "                    execution_time += 30\n",
    "            while jobs_submitted < total_jobs:\n",
    "                for burst in bursts:\n",
    "                    if execution_time == burst[0]:\n",
    "                        burst_cpu_limit = burst[1]\n",
    "                        burst_mem_limit = burst[2]\n",
    "                        burst_total_jobs = burst[3]\n",
    "                        burst_sleep_time = burst[4]\n",
    "                        print(\"Submitting burst at \" + str(execution_time))\n",
    "                        k8s.submit_burst(namespace, scheduler_name, burst_cpu_limit, burst_mem_limit, burst_total_jobs, burst_sleep_time)\n",
    "\n",
    "                if int(cpu_limit) > 0:\n",
    "                    container = k8s.create_container(image, container_name, pull_policy, cpu_limit, mem_limit, sleep_time)\n",
    "\n",
    "                    pod_id = uuid.uuid4()\n",
    "                    job_id = pod_id\n",
    "                    # create template\n",
    "                    _pod_name = f\"{namespace}-pod-{pod_id}\"\n",
    "                    if namespace == \"backfill\":\n",
    "                        _pod_name = \"tenant-\" + _pod_name\n",
    "                    _pod_spec = k8s.create_pod_template(namespace, _pod_name, container, scheduler_name)\n",
    "\n",
    "                    # create job\n",
    "                    _job_name = f\"{namespace}-{job_id}\"\n",
    "                    if namespace == \"backfill\":\n",
    "                        _job_name = \"tenant-\" + _job_name\n",
    "                    _job = k8s.create_job(_job_name, _pod_spec)\n",
    "\n",
    "                    # execute job\n",
    "                    batch_api = client.BatchV1Api()\n",
    "                    batch_api.create_namespaced_job(namespace, _job)\n",
    "                jobs_submitted = jobs_submitted + 1\n",
    "                execution_time = execution_time + interval\n",
    "                time.sleep(interval)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f218a86-2d10-4cc1-8f54-77c4547c62cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e7dfa3-ec54-47af-a1ed-8af81c121998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multiprocess import Pool\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import csv\n",
    "import time\n",
    "\n",
    "\n",
    "class Experiment():\n",
    "    def __init__(self, experiment_name, experiment_number, namespaces, scheduler_name, params):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.experiment_number = experiment_number\n",
    "        self.namespaces = namespaces\n",
    "        self.scheduler_name = scheduler_name\n",
    "        self.params = params\n",
    "        self.exp_data = {}\n",
    "        self.k8s = Kubernetes()\n",
    "    \n",
    "    def calculate_total_completed(self):\n",
    "        total = 0\n",
    "        for param in self.params:\n",
    "            cores = int(param[1])\n",
    "            num_jobs = param[3]\n",
    "            tenant_total = cores * num_jobs\n",
    "            bursts = param[5]\n",
    "            burst_total = 0\n",
    "            for burst in bursts:\n",
    "                burst_cores = int(burst[1])\n",
    "                burst_num_jobs = burst[3]\n",
    "                burst_total = burst_total + (burst_cores * burst_num_jobs)\n",
    "            total += tenant_total\n",
    "            total += burst_total\n",
    "        return total\n",
    "\n",
    "    def submit_parallel_workflows(self, params):\n",
    "        try:\n",
    "            namespace  = params[0]\n",
    "            cpu_limit  = params[1]\n",
    "            mem_limit  = params[2]\n",
    "            num_jobs   = params[3]\n",
    "            sleep_time = params[4]\n",
    "            bursts     = params[5]\n",
    "            interval   = params[6]\n",
    "            experiment = params[7]\n",
    "            self.k8s.submit_workflow(namespace, self.scheduler_name, cpu_limit, mem_limit, num_jobs, sleep_time, bursts, interval, experiment)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    def start(self):\n",
    "        # yunikorn needs a restart due to some bug?\n",
    "        if self.scheduler_name == \"yunikorn\":\n",
    "            api_response = apps_api.patch_namespaced_deployment_scale(\"yunikorn-scheduler\", \"yunikorn\", {\"spec\": {\"replicas\": 0}})\n",
    "            api_response = apps_api.patch_namespaced_deployment_scale(\"yunikorn-scheduler\", \"yunikorn\", {\"spec\": {\"replicas\": 1}})\n",
    "            time.sleep(2)\n",
    "        try:\n",
    "            # submit multithreaded workflows, one for each tenant\n",
    "            p = Pool(len(self.params))\n",
    "            result = p.map_async(self.submit_parallel_workflows, self.params)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    def cleanup_all_namespaces(self):\n",
    "        namespaces = [\"tenant1\", \"tenant2\", \"tenant3\", \"tenant4\", \"backfill\"]\n",
    "\n",
    "        # clean each namespace of any leftover jobs\n",
    "        for namespace in namespaces:\n",
    "            #k8s.create_namespace(namespace)\n",
    "            self.k8s.delete_all_jobs(namespace)\n",
    "            #k8s.delete_namespace(namespace)\n",
    "\n",
    "        # wait until all the pods are deleted before starting run\n",
    "        cleaned_up = False\n",
    "        while not cleaned_up:\n",
    "            print(\"waiting for pod clean up...\")\n",
    "            all_pods = core_api.list_pod_for_all_namespaces()\n",
    "            all_tenant_pods = [ pod for pod in all_pods.items if \"tenant\" in pod.metadata.name]\n",
    "            if not all_tenant_pods:\n",
    "                print(\"pods are cleaned up!\")\n",
    "                cleaned_up = True\n",
    "            time.sleep(1)\n",
    "\n",
    "                # returns total pending/running/completed cores across all namespaces\n",
    "    def get_totals(self, namespaces):\n",
    "        total_running = 0\n",
    "        total_pending = 0\n",
    "        total_completed = 0\n",
    "        total_preempted = 0\n",
    "        for namespace in namespaces:\n",
    "            if not self.exp_data[namespace+'_pending'] or not self.exp_data[namespace+'_running'] or not self.exp_data[namespace+'_completed'] or not self.exp_data[namespace+'_preempted']:\n",
    "                return 0, 0, 0, 0\n",
    "            total_pending += self.exp_data[namespace+'_pending'][-1] \n",
    "            total_running += self.exp_data[namespace+'_running'][-1]\n",
    "            total_completed += self.exp_data[namespace+'_completed'][-1]\n",
    "            total_preempted += self.exp_data[namespace+'_preempted'][-1]\n",
    "\n",
    "        return total_pending, total_running, total_completed, total_preempted\n",
    "\n",
    "    def monitor(self):\n",
    "        try:\n",
    "            completed_target = self.calculate_total_completed()\n",
    "            # initialize data dictionary\n",
    "            self.exp_data['timestamp'] = [] # empty array for timestamps\n",
    "\n",
    "            for namespace in self.namespaces:\n",
    "                self.exp_data[namespace+'_pending'] = [] # empty array for each namespace's pending jobs\n",
    "                self.exp_data[namespace+'_running'] = [] # empty array for each namespace's running jobs\n",
    "                self.exp_data[namespace+'_completed'] = [] # empty array for each namespace's completed jobs\n",
    "                self.exp_data[namespace+'_preempted'] = [] # empty array for each namespace's preempted jobs\n",
    "\n",
    "            finished = False\n",
    "            timestamp = round(time.time())\n",
    "            while not finished:\n",
    "                #if timestamp == 60:\n",
    "                    #finished = True\n",
    "                # get pods from all namespaces\n",
    "                all_pods = core_api.list_pod_for_all_namespaces()\n",
    "                # get jobs from all namespaces\n",
    "                all_jobs = batch_api.list_job_for_all_namespaces()\n",
    "\n",
    "                # filter for pods with \"tenant\" in the name\n",
    "                all_tenant_pods = [ pod for pod in all_pods.items if \"tenant\" in pod.metadata.name]\n",
    "                all_tenant_jobs = [ job for job in all_jobs.items if \"tenant\" in job.metadata.name]\n",
    "\n",
    "                # insert the timestamp\n",
    "                #exp_data['timestamp'].append(int(time.time())) # epoch time\n",
    "                _time = round(time.time()) - timestamp\n",
    "                self.exp_data['timestamp'].append(_time)\n",
    "\n",
    "                # iterate through namespaces and collect info on pending/running/completed jobs\n",
    "                for namespace in self.namespaces:\n",
    "                    # get pods for the tenant of current namespace\n",
    "                    tenant_pods = [ pod for pod in all_tenant_pods if namespace in pod.metadata.name]\n",
    "                    tenant_jobs = [ job for job in all_tenant_jobs if namespace in job.metadata.name]\n",
    "\n",
    "                    running_cores = 0\n",
    "                    pending_cores = 0\n",
    "                    completed_cores = 0\n",
    "                    preempted_cores = 0\n",
    "\n",
    "                    # loop through pods \n",
    "                    for pod in tenant_pods:\n",
    "                        cores = int(pod.spec.containers[0].resources.limits['cpu'])\n",
    "                        if pod.status.phase == \"Pending\":\n",
    "                            pending_cores = pending_cores + cores\n",
    "                        elif pod.status.phase == \"Running\":\n",
    "                            running_cores = running_cores + cores\n",
    "                        elif pod.status.phase == \"Succeeded\":\n",
    "                            completed_cores = completed_cores + cores\n",
    "\n",
    "                    # check for pending jobs - jobs that are unable to submit a pod due to quota limits\n",
    "                    for job in tenant_jobs:\n",
    "                        has_pod = False\n",
    "                        job_name = job.metadata.name\n",
    "                        for pod in tenant_pods:\n",
    "                            if job_name in pod.metadata.name:\n",
    "                                has_pod = True\n",
    "                        job_cores = int(job.spec.template.spec.containers[0].resources.limits['cpu'])\n",
    "                        if not has_pod and job.status.active is None and job.status.terminating is None and job.status.succeeded is None and job.status.completion_time is None and job.status.ready == 0 and job.status.conditions is None :\n",
    "                            pending_cores = pending_cores + job_cores\n",
    "                        if job.status.failed is not None:\n",
    "                            preempted_cores += job_cores\n",
    "\n",
    "                    self.exp_data[namespace+'_pending'].append(pending_cores)\n",
    "                    self.exp_data[namespace+'_running'].append(running_cores)\n",
    "                    self.exp_data[namespace+'_completed'].append(completed_cores)\n",
    "                    self.exp_data[namespace+'_preempted'].append(preempted_cores)\n",
    "\n",
    "\n",
    "                # check to see if there are still any running or pending jobs\n",
    "                total_pending, total_running, total_completed, total_preempted = self.get_totals(self.namespaces)\n",
    "                print(\"time\", round(time.time()), \"timestamp\", _time, \"pending\", total_pending, \"running\", total_running, \"completed\", total_completed, \"preempted\", total_preempted)\n",
    "                #if total_pending == 0 and total_running == 0 and total_completed > 0:\n",
    "                if total_completed >= completed_target:\n",
    "                    finished = True\n",
    "                #timestamp += 1\n",
    "                time.sleep(1)\n",
    "            print(\"all done!\")\n",
    "            return self.exp_data\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    def graph(self):\n",
    "\n",
    "        results_location = \"results\" + os.path.sep + self.experiment_name.split(\"-\")[0] + os.path.sep + self.experiment_name + \"-\" + self.scheduler_name + \"-run\" + self.experiment_number\n",
    "        exp_full_dataframe = pd.DataFrame(self.exp_data)\n",
    "        exp_full_dataframe.to_csv(results_location + \"-rawdata.csv\", index=False)\n",
    "\n",
    "        exp_data_copy = self.exp_data.copy()\n",
    "        # for graph, remove completed pods\n",
    "        for namespace in self.namespaces:\n",
    "            self.exp_data.pop(namespace+'_completed')\n",
    "\n",
    "        exp_dataframe = pd.DataFrame(self.exp_data)\n",
    "\n",
    "        color = [\"blue\", \"blue\", \"blue\", \"green\", \"green\", \"green\", \"red\", \"red\", \"red\", \"orange\", \"orange\", \"orange\"]\n",
    "        style = [\"--\",   \"-\",    \".-\",   \"--\",    \"-\",     \".-\",    \"--\",  \"-\",   \".-\",  \"--\",     \"-\",      \".-\"]\n",
    "\n",
    "        plot = exp_dataframe.plot(x=\"timestamp\", figsize=(20,10), color=color, style=style, fontsize=\"14\", lw=2)\n",
    "        plot.set_xlabel(\"Run time (seconds)\", fontsize=16)\n",
    "        plot.set_ylabel(\"Number of Cores\", fontsize=16)\n",
    "        #plot.legend(fontsize=14, bbox_to_anchor=(1.19, 0.6), loc=\"center right\")\n",
    "        plot.legend(fontsize=14)\n",
    "\n",
    "        figure = plot.figure\n",
    "        #figure.tight_layout()\n",
    "        figure.savefig(results_location + \"-graph-preemption.png\")\n",
    "\n",
    "        # for graph, remove completed pods\n",
    "        for namespace in self.namespaces:\n",
    "            self.exp_data.pop(namespace+'_preempted')\n",
    "\n",
    "        exp_dataframe = pd.DataFrame(self.exp_data)\n",
    "\n",
    "        color = [\"blue\", \"blue\", \"green\", \"green\", \"red\", \"red\", \"orange\", \"orange\"]\n",
    "        style = [\"--\",   \"-\",    \"--\",    \"-\",     \"--\",  \"-\",   \"--\",     \"-\"]\n",
    "\n",
    "        plot = exp_dataframe.plot(x=\"timestamp\", figsize=(20,10), color=color, style=style, fontsize=\"14\", lw=2)\n",
    "        plot.set_xlabel(\"Run time (seconds)\", fontsize=16)\n",
    "        plot.set_ylabel(\"Number of Cores\", fontsize=16)\n",
    "        plot.legend(fontsize=14)\n",
    "        #plot.legend(fontsize=14, bbox_to_anchor=(1.19, 0.6), loc=\"center right\")\n",
    "\n",
    "        figure = plot.figure\n",
    "        figure.savefig(results_location + \"-graph.png\")\n",
    "        \n",
    "    def save_results(self):\n",
    "        all_pods = core_api.list_pod_for_all_namespaces()\n",
    "        all_jobs = batch_api.list_job_for_all_namespaces()\n",
    "        # filter for pods with \"tenant\" in the name\n",
    "        all_tenant_pods = [ pod for pod in all_pods.items if \"tenant\" in pod.metadata.name]\n",
    "        all_tenant_jobs = [ job for job in all_jobs.items if \"tenant\" in job.metadata.name]   \n",
    "\n",
    "        # set up output csv for dependent variables\n",
    "        results_location = \"results\" + os.path.sep + self.experiment_name.split(\"-\")[0] + os.path.sep + self.experiment_name + \"-\" + self.scheduler_name + \"-run\" + self.experiment_number\n",
    "        output_csv = results_location + \"-depvars.csv\"\n",
    "        output_fields = [\"experiment\", \"run\", \"tenant\", \"total cores\", \"total queue time\", \"avg queue time\", \"total job run time\", \"total queue + job run time\", \"workflow run time (makespan)\"]\n",
    "        output_rows = []\n",
    "\n",
    "        for namespace in self.namespaces:\n",
    "            tenant_pods = [ pod for pod in all_tenant_pods if namespace in pod.metadata.name]\n",
    "            tenant_jobs = [ job for job in all_tenant_jobs if namespace in job.metadata.name]\n",
    "\n",
    "            total_cores = 0\n",
    "            total_queue_time = 0\n",
    "            total_run_time = 0\n",
    "            total_time = 0\n",
    "\n",
    "            # start/end used to calculate makespan\n",
    "            start = None\n",
    "            end = None\n",
    "            makespan = 0\n",
    "            for pod in tenant_pods:\n",
    "                cores = int(pod.spec.containers[0].resources.limits['cpu'])\n",
    "                total_cores += cores\n",
    "                pod_schedule_time = pod.metadata.creation_timestamp\n",
    "                if namespace == \"backfill\":\n",
    "                    job_name = pod.metadata.name[:-5]\n",
    "                else:\n",
    "                    job_name = pod.metadata.name[:-6]\n",
    "                for job in tenant_jobs:\n",
    "                    if job.metadata.name == job_name:\n",
    "                        schedule_time = job.metadata.creation_timestamp\n",
    "                #pod_start_time = pod.status.start_time\n",
    "                pod_start_time = pod.status.container_statuses[0].state.terminated.started_at\n",
    "                pod_end_time = pod.status.container_statuses[0].state.terminated.finished_at\n",
    "                pod_queue_time = pod_start_time - schedule_time\n",
    "                pod_run_time = pod_end_time - pod_start_time\n",
    "                pod_total_time = pod_end_time - schedule_time\n",
    "                total_queue_time = total_queue_time + int(pod_queue_time.total_seconds())\n",
    "                total_run_time = total_run_time + int(pod_run_time.total_seconds())\n",
    "                total_time = total_time + int(pod_total_time.total_seconds())\n",
    "                # calculate makespan\n",
    "                if not start or schedule_time < start:\n",
    "                    start = schedule_time\n",
    "                if not end or pod_end_time > end:\n",
    "                    end = pod_end_time\n",
    "            average_queue_time = round(total_queue_time / len(tenant_pods))\n",
    "            print(namespace, \"Total queue time:\", total_queue_time)\n",
    "            print(namespace, \"Average queue time:\", average_queue_time)\n",
    "            print(namespace, \"Total run time for all jobs:\", total_run_time)\n",
    "            print(namespace, \"Total queue + run time for all jobs:\", total_time)\n",
    "            makespan = round((end - start).total_seconds())\n",
    "            print(namespace, \"Total workflow run time (makespan):\", makespan)\n",
    "            output_rows.append([self.experiment_name, self.experiment_number, namespace, total_cores, total_queue_time, average_queue_time, total_run_time, total_time, makespan])\n",
    "\n",
    "        with open(output_csv, 'w') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            csvwriter.writerow(output_fields)\n",
    "            csvwriter.writerows(output_rows)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c41d0-2599-4b96-9c44-b53587d9e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s = Kubernetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d3cf55-63eb-4fe3-b083-b123012bee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(experiment_name, namespaces, params, schedulers):\n",
    "    for scheduler in schedulers:\n",
    "        for experiment_number in range(1,6):\n",
    "            exp = Experiment(experiment_name, str(experiment_number), namespaces, scheduler, params)\n",
    "            completed_target = exp.calculate_total_completed()\n",
    "            logging.info(\"Starting experiment \" + experiment_name + \" run \" + str(experiment_number) + \" with \" + str(completed_target) + \" total cores requested using \" + scheduler)\n",
    "            exp.cleanup_all_namespaces()\n",
    "            exp.start()\n",
    "            exp.monitor()\n",
    "            exp.graph()\n",
    "            exp.save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177152da-02ed-49e1-ad99-bc8ef52dcd6a",
   "metadata": {},
   "source": [
    "## Section 3.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1addce-096d-476e-a597-a5347a90c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f quotas/tenant1-quota.yaml\n",
    "!kubectl apply -f quotas/tenant2-quota.yaml\n",
    "!kubectl apply -f quotas/tenant3-quota.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da635527-2b82-44cd-a794-c9b83e75db3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"E2\"\n",
    "namespaces = [\"tenant1\", \"tenant2\", \"tenant3\"]\n",
    "schedulers = [\"default-scheduler\"]\n",
    "#schedulers = [\"scheduler-plugins-scheduler\"]\n",
    "#schedulers = [\"yunikorn\"]\n",
    "\n",
    "\n",
    "# [start_time, cpu_limit, mem_limit, num_jobs, sleep_time]\n",
    "# cms\n",
    "bursts_tenant1 = [\n",
    "    [0,  \"4\", \"8G\", 96, \"180\"],\n",
    "    [90, \"4\", \"8G\", 96, \"180\"]\n",
    "]\n",
    "\n",
    "# ag\n",
    "bursts_tenant2 = [\n",
    "    [30,  \"4\", \"8G\", 32, \"120\"],\n",
    "    [120, \"4\", \"8G\", 32, \"120\"]\n",
    "] \n",
    "\n",
    "# ds\n",
    "bursts_tenant3 = [\n",
    "    [150, \"2\", \"4G\", 96, \"60\"]\n",
    "\n",
    "]\n",
    "\n",
    "# use \"0\" for cpu_limit to not submit jobs, only bursts\n",
    "params = [\n",
    "    [\"tenant1\", \"0\", \"4G\", 100, \"60\", bursts_tenant1, 1, experiment_name],\n",
    "    [\"tenant2\", \"0\", \"4G\", 130, \"60\", bursts_tenant2, 1, experiment_name],\n",
    "    [\"tenant3\", \"2\", \"4G\", 25, \"60\", bursts_tenant3, 5, experiment_name],\n",
    "]\n",
    "\n",
    "run_experiment(experiment_name, namespaces, params, schedulers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c991a7b1-76f3-44da-881c-a5cfd19d009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f quotas/tenant1-quota.yaml\n",
    "!kubectl delete -f quotas/tenant2-quota.yaml\n",
    "!kubectl delete -f quotas/tenant3-quota.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4396ab05-ea94-4aaf-9356-89bed0d38a1f",
   "metadata": {},
   "source": [
    "## Section 3.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf78b7c-f92e-4c8a-a755-82605799b354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"E4\"\n",
    "namespaces = [\"tenant1\", \"tenant2\", \"tenant3\"]\n",
    "schedulers = [\"default-scheduler\"]\n",
    "#schedulers = [\"scheduler-plugins-scheduler\"]\n",
    "#schedulers = [\"yunikorn\"]\n",
    "\n",
    "# [start_time, cpu_limit, mem_limit, num_jobs, sleep_time]\n",
    "# cms\n",
    "bursts_tenant1 = [\n",
    "    [0,  \"4\", \"8G\", 96, \"180\"],\n",
    "    [90, \"4\", \"8G\", 96, \"180\"]\n",
    "]\n",
    "\n",
    "# ag\n",
    "bursts_tenant2 = [\n",
    "    [30,  \"4\", \"8G\", 32, \"120\"],\n",
    "    [120, \"4\", \"8G\", 32, \"120\"]\n",
    "] \n",
    "\n",
    "# ds\n",
    "bursts_tenant3 = [\n",
    "    [150, \"2\", \"4G\", 96, \"60\"]\n",
    "\n",
    "]\n",
    "\n",
    "# use \"0\" for cpu_limit to not submit jobs, only bursts\n",
    "params = [\n",
    "    [\"tenant1\", \"0\", \"4G\", 100, \"60\", bursts_tenant1, 1, experiment_name],\n",
    "    [\"tenant2\", \"0\", \"4G\", 130, \"60\", bursts_tenant2, 1, experiment_name],\n",
    "    [\"tenant3\", \"2\", \"4G\", 25, \"60\", bursts_tenant3, 5, experiment_name],\n",
    "]\n",
    "\n",
    "run_experiment(experiment_name, namespaces, params, schedulers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
