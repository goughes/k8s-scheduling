{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9d550-822c-4ebf-bea2-55b5740d62dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, uuid, time, csv\n",
    "\n",
    "from kubernetes import client, config, watch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "config.load_kube_config(\"/home/goughes/k8s/configs/erikdev-admin.yaml\")\n",
    "core_api = client.CoreV1Api()\n",
    "batch_api = client.BatchV1Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ec392-3cac-4d22-aed2-9744e3d8c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://medium.com/@aris.david/how-to-create-a-job-using-kubernetes-python-client-ed00ac2b791d\n",
    "class Kubernetes:\n",
    "    def __init__(self):\n",
    "\n",
    "        # Init Kubernetes\n",
    "        self.core_api = client.CoreV1Api()\n",
    "        self.batch_api = client.BatchV1Api()\n",
    "\n",
    "    def get_all_namespaces(self):\n",
    "        namespaces = self.core_api.list_namespace()\n",
    "        all_namespaces = []\n",
    "        for ns in namespaces.items:\n",
    "            all_namespaces.append(ns.metadata.name)\n",
    "        return all_namespaces\n",
    "            \n",
    "    def create_namespace(self, namespace):\n",
    "\n",
    "        all_namespaces = self.get_all_namespaces()\n",
    "\n",
    "        if namespace in all_namespaces:\n",
    "            logging.info(f\"Namespace {namespace} already exists. Reusing.\")\n",
    "        else:\n",
    "            namespace_metadata = client.V1ObjectMeta(name=namespace)\n",
    "            self.core_api.create_namespace(\n",
    "                client.V1Namespace(metadata=namespace_metadata)\n",
    "            )\n",
    "            logging.info(f\"Created namespace {namespace}.\")\n",
    "\n",
    "        return namespace\n",
    "    \n",
    "    def delete_namespace(self, namespace):\n",
    "        all_namespaces = self.get_all_namespaces()\n",
    "        \n",
    "        if namespace not in all_namespaces:\n",
    "            logging.info(f\"Namespace {namespace} does not exist.\")\n",
    "        else:\n",
    "            self.core_api.delete_namespace(name=namespace)\n",
    "            logging.info(f\"Deleted namespace {namespace}.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def create_container(image, name, pull_policy, cpu_limit, mem_limit, sleep_time):\n",
    "\n",
    "        resources = client.V1ResourceRequirements(\n",
    "            requests={\"cpu\": cpu_limit, \"memory\": mem_limit},\n",
    "            limits={\"cpu\": cpu_limit, \"memory\": mem_limit}\n",
    "        )\n",
    "            \n",
    "        container = client.V1Container(\n",
    "            image=image,\n",
    "            name=name,\n",
    "            resources=resources,\n",
    "            image_pull_policy=pull_policy,\n",
    "            args=[sleep_time],\n",
    "            command=[\"sleep\"],\n",
    "        )\n",
    "\n",
    "        logging.info(\n",
    "            f\"Created sleep container with name: {container.name}, \"\n",
    "            f\"image: {container.image} and args: {container.args}\"\n",
    "        )\n",
    "\n",
    "        return container\n",
    "\n",
    "    @staticmethod\n",
    "    def create_pod_template(pod_name, container, scheduler_name):\n",
    "        pod_template = client.V1PodTemplateSpec(\n",
    "            spec=client.V1PodSpec(restart_policy=\"Never\", containers=[container], scheduler_name=scheduler_name),\n",
    "            metadata=client.V1ObjectMeta(name=pod_name, labels={\"pod_name\": pod_name, \"applicationId\": pod_name.split(\"-\")[-1], \"queue\": \"root.sandbox.tenants.\" + pod_name.split(\"-\")[0]}),\n",
    "        )\n",
    "\n",
    "        return pod_template\n",
    "\n",
    "    @staticmethod\n",
    "    def create_job(job_name, pod_template):\n",
    "        metadata = client.V1ObjectMeta(name=job_name, labels={\"job_name\": job_name})\n",
    "\n",
    "        job = client.V1Job(\n",
    "            api_version=\"batch/v1\",\n",
    "            kind=\"Job\",\n",
    "            metadata=metadata,\n",
    "            #spec=client.V1JobSpec(backoff_limit=6, template=pod_template),\n",
    "            spec=client.V1JobSpec(template=pod_template),\n",
    "        )\n",
    "\n",
    "        return job\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_all_pods(namespace):\n",
    "        pods = core_api.list_namespaced_pod(namespace, pretty=True, timeout_seconds=60)\n",
    "        print(\"number of pods: \" + str(len(pods.items)))\n",
    "        return pods\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_all_jobs(namespace):\n",
    "        jobs = batch_api.list_namespaced_job(namespace, pretty=True, timeout_seconds=60)\n",
    "        print(\"number of jobs: \" + str(len(jobs.items)))\n",
    "        return jobs\n",
    "    \n",
    "    @staticmethod\n",
    "    def delete_all_jobs(namespace):\n",
    "        jobs = batch_api.list_namespaced_job(namespace, pretty=True, timeout_seconds=60)\n",
    "        deleteoptions = client.V1DeleteOptions()\n",
    "        for job in jobs.items:\n",
    "            print(\"Deleting job \" + job.metadata.name)\n",
    "            jobname = job.metadata.name\n",
    "            api_response = batch_api.delete_namespaced_job(jobname,\n",
    "                                                           namespace,\n",
    "                                                           grace_period_seconds=0, \n",
    "                                                           propagation_policy='Background')\n",
    "            logging.debug(api_response)\n",
    "    \n",
    "    \"\"\"\n",
    "        interval: time to wait/sleep between each job submission\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def submit_burst(namespace, scheduler_name, cpu_limit, mem_limit, total_jobs, sleep_time):\n",
    "        try:\n",
    "            image = \"busybox:1.36\"\n",
    "            name = \"burst-sleep-\" + namespace\n",
    "            pull_policy = \"Never\"\n",
    "            print(\"bursting\", total_jobs, \"sleep\", sleep_time)\n",
    "            burst_submitted = 0\n",
    "            while burst_submitted < total_jobs:\n",
    "                container = k8s.create_container(image, name, pull_policy, cpu_limit, mem_limit, sleep_time)\n",
    "\n",
    "                pod_id = uuid.uuid4()\n",
    "                job_id = pod_id\n",
    "                # create template\n",
    "                _pod_name = f\"{namespace}-burst-pod-{pod_id}\"\n",
    "                _pod_spec = k8s.create_pod_template(_pod_name, container, scheduler_name)\n",
    "\n",
    "                # create job\n",
    "                _job_name = f\"{namespace}-burst-{job_id}\"\n",
    "                _job = k8s.create_job(_job_name, _pod_spec)\n",
    "\n",
    "                # execute job\n",
    "                batch_api = client.BatchV1Api()\n",
    "                batch_api.create_namespaced_job(namespace, _job)\n",
    "                burst_submitted = burst_submitted + 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    @staticmethod\n",
    "    def submit_workflow(namespace, scheduler_name, cpu_limit, mem_limit, total_jobs, sleep_time, bursts, interval):\n",
    "        try:\n",
    "            image = \"busybox:1.36\"\n",
    "            name = \"sleep-\" + namespace\n",
    "            pull_policy = \"Never\"\n",
    "            print(\"submit\")\n",
    "            execution_time = 0\n",
    "            jobs_submitted = 0\n",
    "            while jobs_submitted < total_jobs:\n",
    "                for burst in bursts:\n",
    "                    print(\"check burst\")\n",
    "                    if execution_time == burst[0]:\n",
    "                        print(\"burst\")\n",
    "                        burst_cpu_limit = burst[1]\n",
    "                        burst_mem_limit = burst[2]\n",
    "                        burst_total_jobs = burst[3]\n",
    "                        burst_sleep_time = burst[4]\n",
    "                        print(\"Submitting burst at \" + str(execution_time))\n",
    "                        k8s.submit_burst(namespace, scheduler_name, burst_cpu_limit, burst_mem_limit, burst_total_jobs, burst_sleep_time)\n",
    "\n",
    "                if int(cpu_limit) > 0:\n",
    "                    container = k8s.create_container(image, name, pull_policy, cpu_limit, mem_limit, sleep_time)\n",
    "\n",
    "                    pod_id = uuid.uuid4()\n",
    "                    job_id = pod_id\n",
    "                    # create template\n",
    "                    _pod_name = f\"{namespace}-pod-{pod_id}\"\n",
    "                    _pod_spec = k8s.create_pod_template(_pod_name, container, scheduler_name)\n",
    "\n",
    "                    # create job\n",
    "                    _job_name = f\"{namespace}-{job_id}\"\n",
    "                    _job = k8s.create_job(_job_name, _pod_spec)\n",
    "\n",
    "                    # execute job\n",
    "                    batch_api = client.BatchV1Api()\n",
    "                    batch_api.create_namespaced_job(namespace, _job)\n",
    "                jobs_submitted = jobs_submitted + 1\n",
    "                execution_time = execution_time + interval\n",
    "                time.sleep(interval)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b674c64-1bf5-4dbf-9c81-104e280efd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Workflow:\n",
    "    def __init__(self, namespace, scheduler, bursts, params):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d5339-c413-4e4c-a67b-fbe89671d3bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "k8s = Kubernetes()\n",
    "\n",
    "#namespaces = [\"tenant1\"]#, \"tenant2\"]#, \"tenant3\"]\n",
    "namespaces = [\"tenant1\", \"tenant2\", \"tenant3\", \"tenant4\"]\n",
    "\n",
    "# clean each namespace of any leftover jobs\n",
    "for namespace in namespaces:\n",
    "    #k8s.create_namespace(namespace)\n",
    "    k8s.delete_all_jobs(namespace)\n",
    "    #k8s.delete_namespace(namespace)\n",
    "    \n",
    "# wait until all the pods are deleted before starting run\n",
    "cleaned_up = False\n",
    "while not cleaned_up:\n",
    "    print(\"waiting for pod clean up...\")\n",
    "    all_pods = core_api.list_pod_for_all_namespaces()\n",
    "    all_tenant_pods = [ pod for pod in all_pods.items if \"tenant\" in pod.metadata.name]\n",
    "    if not all_tenant_pods:\n",
    "        print(\"pods are cleaned up!\")\n",
    "        cleaned_up = True\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8390ef6-954e-4da0-8617-da93c5d2b0a0",
   "metadata": {},
   "source": [
    "# cms\n",
    "# demand = whole cluster\n",
    "bursts_tenant1 = [\n",
    "    [5, \"4\", \"8G\", 60, \"90\"],\n",
    "    [60, \"4\", \"8G\", 60, \"20\"]\n",
    "]\n",
    "params = [\n",
    "    [\"tenant1\", \"0\", \"8G\", 120, \"60\", bursts_tenant1, 1],\n",
    "]\n",
    "\n",
    "# ag\n",
    "# demand = 2x quota\n",
    "\n",
    "# ds\n",
    "# demand = 4x quota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b32956-ad19-4f0c-8d21-8e798e07e9b6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "experiment_name = \"E5\"\n",
    "experiment_number = \"1\"\n",
    "\n",
    "#namespaces = [\"tenant1\", \"tenant2\"]\n",
    "#namespaces = [\"tenant1\", \"tenant2\", \"tenant3\"]\n",
    "namespaces = [\"tenant1\", \"tenant2\", \"tenant3\", \"tenant4\"]\n",
    "\n",
    "#scheduler_name = \"scheduler-plugins-scheduler\"\n",
    "#scheduler_name = \"nos-scheduler\"\n",
    "scheduler_name = \"yunikorn\"\n",
    "\n",
    "\n",
    "# [start_time, cpu_limit, mem_limit, num_jobs, sleep_time]\n",
    "# cms\n",
    "bursts_tenant1 = [\n",
    "    [10,  \"4\", \"8G\", 96, \"300\"],\n",
    "    [60, \"4\", \"8G\", 96, \"300\"]\n",
    "]\n",
    "\n",
    "bursts_tenant2 = [\n",
    "    [5,  \"4\", \"8G\", 96, \"120\"],\n",
    "    [70, \"4\", \"8G\", 96, \"120\"]\n",
    "]\n",
    "\n",
    "# ag\n",
    "#bursts_tenant2 = [\n",
    "#    [0,  \"2\", \"4G\", 64, \"30\"],\n",
    "#    [45, \"2\", \"4G\", 64, \"30\"],\n",
    "#    [90, \"2\", \"4G\", 64, \"30\"]\n",
    "\n",
    "#]\n",
    "\n",
    "# ds\n",
    "bursts_tenant3 = [\n",
    "    [200, \"2\", \"4G\", 48, \"60\"],\n",
    "    [230, \"2\", \"4G\", 96, \"60\"]\n",
    "\n",
    "]\n",
    "\n",
    "# backfill\n",
    "bursts_tenant4 = [\n",
    "    [1, \"8\", \"16G\", 48, \"600\"],\n",
    "]\n",
    "\n",
    "# format of parameters list of lists\n",
    "# params = [\n",
    "#     [namespace1, cpu_limit, mem_limit, num_jobs, sleep_time, submission_interval],\n",
    "#     [namespace2, cpu_limit, mem_limit, num_jobs, sleep_time, submission_interval],\n",
    "# ]\n",
    "\n",
    "\n",
    "# use \"0\" for cpu_limit to not submit jobs, only bursts\n",
    "params = [\n",
    "    [\"tenant1\", \"0\", \"4G\", 120, \"60\", bursts_tenant1, 1],\n",
    "    [\"tenant2\", \"0\", \"4G\", 120, \"60\", bursts_tenant2, 1],\n",
    "    [\"tenant3\", \"2\", \"4G\", 48, \"60\", bursts_tenant3, 5],\n",
    "    [\"tenant4\", \"0\", \"4G\", 120, \"60\", bursts_tenant4, 1], \n",
    "\n",
    "]\n",
    "#[\"tenant2\", \"1\", \"2G\", 750, \"60\", 1.5],\n",
    "#[\"tenant3\", \"1\", \"2G\", 500, \"60\", 2]\n",
    "\n",
    "\n",
    "\n",
    "def calculate_total_completed(params):\n",
    "    total = 0\n",
    "    for param in params:\n",
    "        cores = int(param[1])\n",
    "        num_jobs = param[3]\n",
    "        tenant_total = cores * num_jobs\n",
    "        bursts = param[5]\n",
    "        burst_total = 0\n",
    "        for burst in bursts:\n",
    "            burst_cores = int(burst[1])\n",
    "            burst_num_jobs = burst[3]\n",
    "            burst_total = burst_total + (burst_cores * burst_num_jobs)\n",
    "        total += tenant_total\n",
    "        total += burst_total\n",
    "    return total\n",
    "        \n",
    "completed_target = calculate_total_completed(params)\n",
    "print(completed_target)\n",
    "\n",
    "from multiprocess import Pool\n",
    "\n",
    "def submit_parallel_workflows(params):\n",
    "    namespace  = params[0]\n",
    "    cpu_limit  = params[1]\n",
    "    mem_limit  = params[2]\n",
    "    num_jobs   = params[3]\n",
    "    sleep_time = params[4]\n",
    "    bursts     = params[5]\n",
    "    interval   = params[6]\n",
    "    k8s.submit_workflow(namespace, scheduler_name, cpu_limit, mem_limit, num_jobs, sleep_time, bursts, interval)\n",
    "\n",
    "# submit multithreaded workflows, one for each tenant\n",
    "p = Pool(len(params))\n",
    "result = p.map_async(submit_parallel_workflows, params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c9eb9-e360-485c-be78-e7dc414d9af1",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### Dictionary format used to store experiment data\n",
    "\n",
    "Assuming `namespaces = [\"tenant1\", \"tenant2\", \"tenant3\"]` the dictionary would be created as follows:\n",
    "```\n",
    "data = {\n",
    "    'timestamp':[1,2,3,4,5],\n",
    "    'tenant1_pending':[3,4,3,4,5],\n",
    "    'tenant1_running':[5,6,5,6,5],\n",
    "    'tenant1_completed':[7,6,7,8,7],\n",
    "    'tenant2_pending':[1,1,1,1,1],\n",
    "    'tenant2_running':[2,2,2,2,2],\n",
    "    'tenant2_completed':[3,3,3,3,3],\n",
    "    'tenant3_pending':[2,3,2,3,2],\n",
    "    'tenant3_running':[3,4,3,4,3],\n",
    "    'tenant3_completed':[5,5,5,5,5],\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb617bc-af5e-442a-b505-e04b056527f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "try:\n",
    "    # returns total pending/running/completed cores across all namespaces\n",
    "    def get_totals(namespaces):\n",
    "        total_running = 0\n",
    "        total_pending = 0\n",
    "        total_completed = 0\n",
    "        total_preempted = 0\n",
    "        for namespace in namespaces:\n",
    "            if not exp_data[namespace+'_pending'] or not exp_data[namespace+'_running'] or not exp_data[namespace+'_completed'] or not exp_data[namespace+'_preempted']:\n",
    "                return 0, 0, 0, 0\n",
    "            total_pending += exp_data[namespace+'_pending'][-1] \n",
    "            total_running += exp_data[namespace+'_running'][-1]\n",
    "            total_completed += exp_data[namespace+'_completed'][-1]\n",
    "            total_preempted += exp_data[namespace+'_preempted'][-1]\n",
    "\n",
    "        return total_pending, total_running, total_completed, total_preempted\n",
    "\n",
    "\n",
    "    # initialize data dictionary\n",
    "    exp_data = {}\n",
    "    exp_data['timestamp'] = [] # empty array for timestamps\n",
    "\n",
    "    for namespace in namespaces:\n",
    "        exp_data[namespace+'_pending'] = [] # empty array for each namespace's pending jobs\n",
    "        exp_data[namespace+'_running'] = [] # empty array for each namespace's running jobs\n",
    "        exp_data[namespace+'_completed'] = [] # empty array for each namespace's completed jobs\n",
    "        exp_data[namespace+'_preempted'] = [] # empty array for each namespace's completed jobs\n",
    "\n",
    "\n",
    "\n",
    "    finished = False\n",
    "    timestamp = 0\n",
    "    while not finished:\n",
    "        # get pods from all namespaces\n",
    "        all_pods = core_api.list_pod_for_all_namespaces()\n",
    "        # get jobs from all namespaces\n",
    "        all_jobs = batch_api.list_job_for_all_namespaces()\n",
    "\n",
    "        # filter for pods with \"tenant\" in the name\n",
    "        all_tenant_pods = [ pod for pod in all_pods.items if \"tenant\" in pod.metadata.name]\n",
    "        all_tenant_jobs = [ job for job in all_jobs.items if \"tenant\" in job.metadata.name]\n",
    "\n",
    "        # insert the timestamp\n",
    "        #exp_data['timestamp'].append(int(time.time())) # epoch time\n",
    "        exp_data['timestamp'].append(timestamp)\n",
    "\n",
    "        # iterate through namespaces and collect info on pending/running/completed jobs\n",
    "        for namespace in namespaces:\n",
    "            # get pods for the tenant of current namespace\n",
    "            tenant_pods = [ pod for pod in all_tenant_pods if namespace in pod.metadata.name]\n",
    "            tenant_jobs = [ job for job in all_tenant_jobs if namespace in job.metadata.name]\n",
    "\n",
    "            running_cores = 0\n",
    "            pending_cores = 0\n",
    "            completed_cores = 0\n",
    "            preempted_cores = 0\n",
    "\n",
    "            # loop through pods \n",
    "            for pod in tenant_pods:\n",
    "                cores = int(pod.spec.containers[0].resources.limits['cpu'])\n",
    "                if pod.status.phase == \"Pending\":\n",
    "                    pending_cores = pending_cores + cores\n",
    "                elif pod.status.phase == \"Running\":\n",
    "                    running_cores = running_cores + cores\n",
    "                elif pod.status.phase == \"Succeeded\":\n",
    "                    completed_cores = completed_cores + cores\n",
    "\n",
    "            # check for pending jobs - jobs that are unable to submit a pod due to quota limits\n",
    "            for job in tenant_jobs:\n",
    "                has_pod = False\n",
    "                job_name = job.metadata.name\n",
    "                for pod in tenant_pods:\n",
    "                    if job_name in pod.metadata.name:\n",
    "                        has_pod = True\n",
    "                job_cores = int(job.spec.template.spec.containers[0].resources.limits['cpu'])\n",
    "                if not has_pod and job.status.active is None and job.status.terminating is None and job.status.succeeded is None and job.status.completion_time is None and job.status.ready == 0 and job.status.conditions is None :\n",
    "                    pending_cores = pending_cores + job_cores\n",
    "                if job.status.failed is not None:\n",
    "                    preempted_cores += job_cores\n",
    "                    \n",
    "            exp_data[namespace+'_pending'].append(pending_cores)\n",
    "            exp_data[namespace+'_running'].append(running_cores)\n",
    "            exp_data[namespace+'_completed'].append(completed_cores)\n",
    "            exp_data[namespace+'_preempted'].append(preempted_cores)\n",
    "\n",
    "\n",
    "        # check to see if there are still any running or pending jobs\n",
    "        total_pending, total_running, total_completed, total_preempted = get_totals(namespaces)\n",
    "        print(\"pending\", total_pending, \"running\", total_running, \"completed\", total_completed, \"preempted\", total_preempted)\n",
    "        #if total_pending == 0 and total_running == 0 and total_completed > 0:\n",
    "        if total_completed >= completed_target:\n",
    "            finished = True\n",
    "        print(timestamp)\n",
    "        timestamp += 1\n",
    "        time.sleep(1)\n",
    "    print(\"all done!\")\n",
    "    \n",
    "    #pprint.pprint(exp_data)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a75dd-a8a9-4d08-bc0f-24cd3c4ce531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "experiment_name = \"E1\"\n",
    "experiment_number = \"1\"\n",
    "exp_full_dataframe = pd.DataFrame(exp_data)\n",
    "\n",
    "exp_full_dataframe.to_csv(experiment_name + \"-run\" + experiment_number + \"-rawdata.csv\", index=False)\n",
    "\n",
    "# for graph, remove completed pods\n",
    "#for namespace in namespaces:\n",
    "    #exp_data.pop(namespace+'_completed')\n",
    "\n",
    "color = [\"blue\", \"blue\", \"blue\", \"green\", \"green\", \"green\", \"red\", \"red\", \"red\", \"orange\", \"orange\", \"orange\"]\n",
    "style = [\"--\",   \"-\",    \".-\",   \"--\",    \"-\",     \".-\",    \"--\",  \"-\",   \".-\",  \"--\",     \"-\",      \".-\"]\n",
    "\n",
    "plot = pd_data.plot(x=\"timestamp\", figsize=(20,10), color=color, style=style, fontsize=\"14\", lw=2)\n",
    "plot.set_xlabel(\"Run time (seconds)\", fontsize=16)\n",
    "plot.set_ylabel(\"Number of Cores\", fontsize=16)\n",
    "plot.legend(fontsize=14)\n",
    "figure = plot.figure\n",
    "figure.savefig(experiment_name + \"-run\" + experiment_number + \"-graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94111b48-dddb-429d-a3cb-a7161d5fd37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for namespace in namespaces:\n",
    "#    print(exp_data[namespace + '_running'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c770f7f-2e4b-4412-8428-a76cc9ae9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "all_pods = core_api.list_pod_for_all_namespaces()\n",
    "all_jobs = batch_api.list_job_for_all_namespaces()\n",
    "# filter for pods with \"tenant\" in the name\n",
    "all_tenant_pods = [ pod for pod in all_pods.items if \"tenant\" in pod.metadata.name]\n",
    "all_tenant_jobs = [ job for job in all_jobs.items if \"tenant\" in job.metadata.name]   \n",
    "\n",
    "# set up output csv for dependent variables\n",
    "output_csv = experiment_name + \"-run\" + experiment_number + \"-depvars.csv\"\n",
    "output_fields = [\"experiment\", \"run\", \"tenant\", \"total queue time\", \"avg queue time\", \"total job run time\", \"total queue + job run time\", \"workflow run time (makespan)\"]\n",
    "output_rows = []\n",
    "\n",
    "for namespace in namespaces:\n",
    "    tenant_pods = [ pod for pod in all_tenant_pods if namespace in pod.metadata.name]\n",
    "    tenant_jobs = [ job for job in all_tenant_jobs if namespace in job.metadata.name]\n",
    "\n",
    "    \n",
    "    total_queue_time = 0\n",
    "    total_run_time = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    # start/end used to calculate makespan\n",
    "    start = None\n",
    "    end = None\n",
    "    makespan = 0\n",
    "    for pod in tenant_pods:\n",
    "        #print(pod.status.container_statuses[0].state)\n",
    "        pod_schedule_time = pod.metadata.creation_timestamp\n",
    "        job_name = pod.metadata.name[:-6]\n",
    "        for job in tenant_jobs:\n",
    "            if job.metadata.name == job_name:\n",
    "                schedule_time = job.metadata.creation_timestamp\n",
    "        #pod_start_time = pod.status.start_time\n",
    "        pod_start_time = pod.status.container_statuses[0].state.terminated.started_at\n",
    "        pod_end_time = pod.status.container_statuses[0].state.terminated.finished_at\n",
    "        pod_queue_time = pod_start_time - schedule_time\n",
    "        pod_run_time = pod_end_time - pod_start_time\n",
    "        pod_total_time = pod_end_time - schedule_time\n",
    "        total_queue_time = total_queue_time + int(pod_queue_time.total_seconds())\n",
    "        total_run_time = total_run_time + int(pod_run_time.total_seconds())\n",
    "        total_time = total_time + int(pod_total_time.total_seconds())\n",
    "        # calculate makespan\n",
    "        if not start or schedule_time < start:\n",
    "            start = schedule_time\n",
    "        if not end or pod_end_time > end:\n",
    "            end = pod_end_time\n",
    "        #print(pod.metadata.name, pod_start_time, int(pod_queue_time.total_seconds()))\n",
    "    average_queue_time = round(total_queue_time / len(tenant_pods))\n",
    "    print(namespace, \"Total queue time:\", total_queue_time)\n",
    "    print(namespace, \"Average queue time:\", average_queue_time)\n",
    "    print(namespace, \"Total run time for all jobs:\", total_run_time)\n",
    "    print(namespace, \"Total queue + run time for all jobs:\", total_time)\n",
    "    makespan = round((end - start).total_seconds())\n",
    "    print(namespace, \"Total workflow run time (makespan):\", makespan)\n",
    "    output_rows.append([experiment_name, experiment_number, namespace, total_queue_time, average_queue_time, total_run_time, total_time, makespan])\n",
    "\n",
    "print(output_rows)\n",
    "with open(output_csv, 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(output_fields)\n",
    "    csvwriter.writerows(output_rows)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efdb46b-59cb-4921-80a1-8479cf568fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pods = core_api.list_pod_for_all_namespaces()\n",
    "#all_jobs = batch_api.list_job_for_all_namespaces()\n",
    "# filter for pods with \"tenant\" in the name\n",
    "all_tenant_pods = [ pod for pod in all_pods.items if \"tenant\" in pod.metadata.name]\n",
    "#all_tenant_jobs = [ job for job in all_jobs.items if \"tenant\" in job.metadata.name]\n",
    "\n",
    "counts = {'tenant1_pending': 0,\n",
    "          'tenant2_pending': 0,\n",
    "          'tenant3_pending': 0,\n",
    "          'tenant4_pending': 0,\n",
    "          'tenant1_running': 0,\n",
    "          'tenant2_running': 0,\n",
    "          'tenant3_running': 0,\n",
    "          'tenant4_running': 0,\n",
    "          'tenant1_completed': 0,\n",
    "          'tenant2_completed': 0,\n",
    "          'tenant3_completed': 0,\n",
    "          'tenant4_completed': 0,\n",
    "         }\n",
    "\n",
    "for pod in all_tenant_pods:\n",
    "    tenant = pod.metadata.name.split(\"-\")[0]\n",
    "    cores = int(pod.spec.containers[0].resources.limits['cpu'])\n",
    "    if pod.status.phase == \"Pending\":\n",
    "        pending_cores = cores\n",
    "    elif pod.status.phase == \"Running\":\n",
    "        running_cores = cores\n",
    "    elif pod.status.phase == \"Succeeded\":\n",
    "        completed_cores = cores\n",
    "    counts[tenant+'_pending'] += pending_cores\n",
    "    counts[tenant+'_running'] += running_cores \n",
    "    counts[tenant+'_completed'] += completed_cores \n",
    "\n",
    "    #break\n",
    "print(counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137a525-ca38-4565-a2be-8aab41b6677a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0cbc98-2f55-458b-8e99-83e718c1cecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a22960d-59f9-4701-8fb3-1917c08f6c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d00c29-815d-4b7b-9c6a-58195820efca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
