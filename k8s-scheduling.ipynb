{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9d550-822c-4ebf-bea2-55b5740d62dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, uuid, time, csv\n",
    "\n",
    "from kubernetes import client, config, watch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "config.load_kube_config(\"/home/goughes/k8s/configs/erikdev-admin.yaml\")\n",
    "core_api = client.CoreV1Api()\n",
    "batch_api = client.BatchV1Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ec392-3cac-4d22-aed2-9744e3d8c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://medium.com/@aris.david/how-to-create-a-job-using-kubernetes-python-client-ed00ac2b791d\n",
    "class Kubernetes:\n",
    "    def __init__(self):\n",
    "\n",
    "        # Init Kubernetes\n",
    "        self.core_api = client.CoreV1Api()\n",
    "        self.batch_api = client.BatchV1Api()\n",
    "\n",
    "    def get_all_namespaces(self):\n",
    "        namespaces = self.core_api.list_namespace()\n",
    "        all_namespaces = []\n",
    "        for ns in namespaces.items:\n",
    "            all_namespaces.append(ns.metadata.name)\n",
    "        return all_namespaces\n",
    "            \n",
    "    def create_namespace(self, namespace):\n",
    "\n",
    "        all_namespaces = self.get_all_namespaces()\n",
    "\n",
    "        if namespace in all_namespaces:\n",
    "            logging.info(f\"Namespace {namespace} already exists. Reusing.\")\n",
    "        else:\n",
    "            namespace_metadata = client.V1ObjectMeta(name=namespace)\n",
    "            self.core_api.create_namespace(\n",
    "                client.V1Namespace(metadata=namespace_metadata)\n",
    "            )\n",
    "            logging.info(f\"Created namespace {namespace}.\")\n",
    "\n",
    "        return namespace\n",
    "    \n",
    "    def delete_namespace(self, namespace):\n",
    "        all_namespaces = self.get_all_namespaces()\n",
    "        \n",
    "        if namespace not in all_namespaces:\n",
    "            logging.info(f\"Namespace {namespace} does not exist.\")\n",
    "        else:\n",
    "            self.core_api.delete_namespace(name=namespace)\n",
    "            logging.info(f\"Deleted namespace {namespace}.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def create_container(image, name, pull_policy, cpu_limit, mem_limit, sleep_time):\n",
    "\n",
    "        resources = client.V1ResourceRequirements(\n",
    "            requests={\"cpu\": cpu_limit, \"memory\": mem_limit},\n",
    "            limits={\"cpu\": cpu_limit, \"memory\": mem_limit}\n",
    "        )\n",
    "            \n",
    "        container = client.V1Container(\n",
    "            image=image,\n",
    "            name=name,\n",
    "            resources=resources,\n",
    "            image_pull_policy=pull_policy,\n",
    "            args=[sleep_time],\n",
    "            command=[\"sleep\"],\n",
    "        )\n",
    "\n",
    "        logging.info(\n",
    "            f\"Created sleep container with name: {container.name}, \"\n",
    "            f\"image: {container.image} and args: {container.args}\"\n",
    "        )\n",
    "\n",
    "        return container\n",
    "\n",
    "    @staticmethod\n",
    "    def create_pod_template(namespace, pod_name, container, scheduler_name):\n",
    "        pod_template = client.V1PodTemplateSpec(\n",
    "            spec=client.V1PodSpec(restart_policy=\"Never\", containers=[container]),#, scheduler_name=scheduler_name),\n",
    "            metadata=client.V1ObjectMeta(name=pod_name, labels={\"pod_name\": pod_name, \"applicationId\": pod_name.split(\"-\")[-1], \"queue\": \"root.tenants.\" + namespace}),\n",
    "        )\n",
    "\n",
    "        return pod_template\n",
    "\n",
    "    @staticmethod\n",
    "    def create_job(job_name, pod_template):\n",
    "        metadata = client.V1ObjectMeta(name=job_name, labels={\"job_name\": job_name})\n",
    "\n",
    "        job = client.V1Job(\n",
    "            api_version=\"batch/v1\",\n",
    "            kind=\"Job\",\n",
    "            metadata=metadata,\n",
    "            #spec=client.V1JobSpec(backoff_limit=6, template=pod_template),\n",
    "            spec=client.V1JobSpec(template=pod_template),\n",
    "        )\n",
    "\n",
    "        return job\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_all_pods(namespace):\n",
    "        pods = core_api.list_namespaced_pod(namespace, pretty=True, timeout_seconds=60)\n",
    "        print(\"number of pods: \" + str(len(pods.items)))\n",
    "        return pods\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_all_jobs(namespace):\n",
    "        jobs = batch_api.list_namespaced_job(namespace, pretty=True, timeout_seconds=60)\n",
    "        print(\"number of jobs: \" + str(len(jobs.items)))\n",
    "        return jobs\n",
    "    \n",
    "    @staticmethod\n",
    "    def delete_all_jobs(namespace):\n",
    "        jobs = batch_api.list_namespaced_job(namespace, pretty=True, timeout_seconds=60)\n",
    "        deleteoptions = client.V1DeleteOptions()\n",
    "        for job in jobs.items:\n",
    "            print(\"Deleting job \" + job.metadata.name)\n",
    "            jobname = job.metadata.name\n",
    "            api_response = batch_api.delete_namespaced_job(jobname,\n",
    "                                                           namespace,\n",
    "                                                           grace_period_seconds=0, \n",
    "                                                           propagation_policy='Background')\n",
    "            logging.debug(api_response)\n",
    "    \n",
    "    \"\"\"\n",
    "        interval: time to wait/sleep between each job submission\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def submit_burst(namespace, scheduler_name, cpu_limit, mem_limit, total_jobs, sleep_time):\n",
    "        try:\n",
    "            image = \"busybox:1.36\"\n",
    "            container_name = \"burst-sleep-\" + namespace\n",
    "            pull_policy = \"Never\"\n",
    "            print(\"bursting\", total_jobs, \"sleep\", sleep_time)\n",
    "            burst_submitted = 0\n",
    "            while burst_submitted < total_jobs:\n",
    "                container = k8s.create_container(image, container_name, pull_policy, cpu_limit, mem_limit, sleep_time)\n",
    "\n",
    "                pod_id = uuid.uuid4()\n",
    "                job_id = pod_id\n",
    "                # create template\n",
    "                _pod_name = f\"{namespace}-burst-pod-{pod_id}\"\n",
    "                if namespace == \"backfill\":\n",
    "                        _pod_name = \"tenant-\" + _pod_name\n",
    "                _pod_spec = k8s.create_pod_template(namespace, _pod_name, container, scheduler_name)\n",
    "\n",
    "                # create job\n",
    "                _job_name = f\"{namespace}-burst-{job_id}\"\n",
    "                if namespace == \"backfill\":\n",
    "                        _job_name = \"tenant-\" + _job_name\n",
    "                _job = k8s.create_job(_job_name, _pod_spec)\n",
    "\n",
    "                # execute job\n",
    "                batch_api = client.BatchV1Api()\n",
    "                batch_api.create_namespaced_job(namespace, _job)\n",
    "                burst_submitted = burst_submitted + 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    @staticmethod\n",
    "    def submit_workflow(namespace, scheduler_name, cpu_limit, mem_limit, total_jobs, sleep_time, bursts, interval):\n",
    "        try:\n",
    "            print(\"in k8s submit_workflow\")\n",
    "            image = \"busybox:1.36\"\n",
    "            container_name = \"sleep-\" + namespace\n",
    "            pull_policy = \"Never\"\n",
    "            print(\"submit\")\n",
    "            execution_time = 0\n",
    "            jobs_submitted = 0\n",
    "            while jobs_submitted < total_jobs:\n",
    "                for burst in bursts:\n",
    "                    print(\"check burst\")\n",
    "                    if execution_time == burst[0]:\n",
    "                        print(\"burst\")\n",
    "                        burst_cpu_limit = burst[1]\n",
    "                        burst_mem_limit = burst[2]\n",
    "                        burst_total_jobs = burst[3]\n",
    "                        burst_sleep_time = burst[4]\n",
    "                        print(\"Submitting burst at \" + str(execution_time))\n",
    "                        k8s.submit_burst(namespace, scheduler_name, burst_cpu_limit, burst_mem_limit, burst_total_jobs, burst_sleep_time)\n",
    "\n",
    "                if int(cpu_limit) > 0:\n",
    "                    container = k8s.create_container(image, container_name, pull_policy, cpu_limit, mem_limit, sleep_time)\n",
    "\n",
    "                    pod_id = uuid.uuid4()\n",
    "                    job_id = pod_id\n",
    "                    # create template\n",
    "                    _pod_name = f\"{namespace}-pod-{pod_id}\"\n",
    "                    if namespace == \"backfill\":\n",
    "                        _pod_name = \"tenant-\" + _pod_name\n",
    "                    _pod_spec = k8s.create_pod_template(namespace, _pod_name, container, scheduler_name)\n",
    "\n",
    "                    # create job\n",
    "                    _job_name = f\"{namespace}-{job_id}\"\n",
    "                    if namespace == \"backfill\":\n",
    "                        _job_name = \"tenant-\" + _job_name\n",
    "                    _job = k8s.create_job(_job_name, _pod_spec)\n",
    "\n",
    "                    # execute job\n",
    "                    batch_api = client.BatchV1Api()\n",
    "                    batch_api.create_namespaced_job(namespace, _job)\n",
    "                jobs_submitted = jobs_submitted + 1\n",
    "                execution_time = execution_time + interval\n",
    "                time.sleep(interval)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8390ef6-954e-4da0-8617-da93c5d2b0a0",
   "metadata": {},
   "source": [
    "# cms\n",
    "# demand = whole cluster\n",
    "bursts_tenant1 = [\n",
    "    [5, \"4\", \"8G\", 60, \"90\"],\n",
    "    [60, \"4\", \"8G\", 60, \"20\"]\n",
    "]\n",
    "params = [\n",
    "    [\"tenant1\", \"0\", \"8G\", 120, \"60\", bursts_tenant1, 1],\n",
    "]\n",
    "\n",
    "# ag\n",
    "# demand = 2x quota\n",
    "\n",
    "# ds\n",
    "# demand = 4x quota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e7dfa3-ec54-47af-a1ed-8af81c121998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocess import Pool\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import csv\n",
    "\n",
    "\n",
    "class Experiment():\n",
    "    def __init__(self, experiment_name, experiment_number, namespaces, scheduler_name, params):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.experiment_number = experiment_number\n",
    "        self.namespaces = namespaces\n",
    "        self.scheduler_name = scheduler_name\n",
    "        self.params = params\n",
    "        self.exp_data = {}\n",
    "        k8s = Kubernetes()\n",
    "    \n",
    "    def calculate_total_completed(self):\n",
    "        total = 0\n",
    "        for param in self.params:\n",
    "            cores = int(param[1])\n",
    "            num_jobs = param[3]\n",
    "            tenant_total = cores * num_jobs\n",
    "            bursts = param[5]\n",
    "            burst_total = 0\n",
    "            for burst in bursts:\n",
    "                burst_cores = int(burst[1])\n",
    "                burst_num_jobs = burst[3]\n",
    "                burst_total = burst_total + (burst_cores * burst_num_jobs)\n",
    "            total += tenant_total\n",
    "            total += burst_total\n",
    "        return total\n",
    "\n",
    "    def submit_parallel_workflows(self, params):\n",
    "        try:\n",
    "            print(\"in submit_parallel_workflows\")\n",
    "            namespace  = params[0]\n",
    "            cpu_limit  = params[1]\n",
    "            mem_limit  = params[2]\n",
    "            num_jobs   = params[3]\n",
    "            sleep_time = params[4]\n",
    "            bursts     = params[5]\n",
    "            interval   = params[6]\n",
    "            k8s.submit_workflow(namespace, scheduler_name, cpu_limit, mem_limit, num_jobs, sleep_time, bursts, interval)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    def start(self):\n",
    "        print(\"in start\")\n",
    "        try:\n",
    "            # submit multithreaded workflows, one for each tenant\n",
    "            p = Pool(len(self.params))\n",
    "            result = p.map_async(self.submit_parallel_workflows, self.params)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    def cleanup_all_namespaces(self):\n",
    "        namespaces = [\"tenant1\", \"tenant2\", \"tenant3\", \"tenant4\", \"backfill\"]\n",
    "\n",
    "        # clean each namespace of any leftover jobs\n",
    "        for namespace in namespaces:\n",
    "            #k8s.create_namespace(namespace)\n",
    "            k8s.delete_all_jobs(namespace)\n",
    "            #k8s.delete_namespace(namespace)\n",
    "\n",
    "        # wait until all the pods are deleted before starting run\n",
    "        cleaned_up = False\n",
    "        while not cleaned_up:\n",
    "            print(\"waiting for pod clean up...\")\n",
    "            all_pods = core_api.list_pod_for_all_namespaces()\n",
    "            all_tenant_pods = [ pod for pod in all_pods.items if \"tenant\" in pod.metadata.name]\n",
    "            if not all_tenant_pods:\n",
    "                print(\"pods are cleaned up!\")\n",
    "                cleaned_up = True\n",
    "            time.sleep(1)\n",
    "\n",
    "                # returns total pending/running/completed cores across all namespaces\n",
    "    def get_totals(self, namespaces):\n",
    "        total_running = 0\n",
    "        total_pending = 0\n",
    "        total_completed = 0\n",
    "        total_preempted = 0\n",
    "        for namespace in namespaces:\n",
    "            if not self.exp_data[namespace+'_pending'] or not self.exp_data[namespace+'_running'] or not self.exp_data[namespace+'_completed'] or not self.exp_data[namespace+'_preempted']:\n",
    "                return 0, 0, 0, 0\n",
    "            total_pending += self.exp_data[namespace+'_pending'][-1] \n",
    "            total_running += self.exp_data[namespace+'_running'][-1]\n",
    "            total_completed += self.exp_data[namespace+'_completed'][-1]\n",
    "            total_preempted += self.exp_data[namespace+'_preempted'][-1]\n",
    "\n",
    "        return total_pending, total_running, total_completed, total_preempted\n",
    "\n",
    "    def monitor(self):\n",
    "        try:\n",
    "            # initialize data dictionary\n",
    "            self.exp_data['timestamp'] = [] # empty array for timestamps\n",
    "\n",
    "            for namespace in self.namespaces:\n",
    "                self.exp_data[namespace+'_pending'] = [] # empty array for each namespace's pending jobs\n",
    "                self.exp_data[namespace+'_running'] = [] # empty array for each namespace's running jobs\n",
    "                self.exp_data[namespace+'_completed'] = [] # empty array for each namespace's completed jobs\n",
    "                self.exp_data[namespace+'_preempted'] = [] # empty array for each namespace's preempted jobs\n",
    "\n",
    "            finished = False\n",
    "            timestamp = round(time.time())\n",
    "            while not finished:\n",
    "                #if timestamp == 60:\n",
    "                    #finished = True\n",
    "                # get pods from all namespaces\n",
    "                all_pods = core_api.list_pod_for_all_namespaces()\n",
    "                # get jobs from all namespaces\n",
    "                all_jobs = batch_api.list_job_for_all_namespaces()\n",
    "\n",
    "                # filter for pods with \"tenant\" in the name\n",
    "                all_tenant_pods = [ pod for pod in all_pods.items if \"tenant\" in pod.metadata.name]\n",
    "                all_tenant_jobs = [ job for job in all_jobs.items if \"tenant\" in job.metadata.name]\n",
    "\n",
    "                # insert the timestamp\n",
    "                #exp_data['timestamp'].append(int(time.time())) # epoch time\n",
    "                _time = round(time.time()) - timestamp\n",
    "                self.exp_data['timestamp'].append(_time)\n",
    "\n",
    "                # iterate through namespaces and collect info on pending/running/completed jobs\n",
    "                for namespace in self.namespaces:\n",
    "                    # get pods for the tenant of current namespace\n",
    "                    tenant_pods = [ pod for pod in all_tenant_pods if namespace in pod.metadata.name]\n",
    "                    tenant_jobs = [ job for job in all_tenant_jobs if namespace in job.metadata.name]\n",
    "\n",
    "                    running_cores = 0\n",
    "                    pending_cores = 0\n",
    "                    completed_cores = 0\n",
    "                    preempted_cores = 0\n",
    "\n",
    "                    # loop through pods \n",
    "                    for pod in tenant_pods:\n",
    "                        cores = int(pod.spec.containers[0].resources.limits['cpu'])\n",
    "                        if pod.status.phase == \"Pending\":\n",
    "                            pending_cores = pending_cores + cores\n",
    "                        elif pod.status.phase == \"Running\":\n",
    "                            running_cores = running_cores + cores\n",
    "                        elif pod.status.phase == \"Succeeded\":\n",
    "                            completed_cores = completed_cores + cores\n",
    "\n",
    "                    # check for pending jobs - jobs that are unable to submit a pod due to quota limits\n",
    "                    for job in tenant_jobs:\n",
    "                        has_pod = False\n",
    "                        job_name = job.metadata.name\n",
    "                        for pod in tenant_pods:\n",
    "                            if job_name in pod.metadata.name:\n",
    "                                has_pod = True\n",
    "                        job_cores = int(job.spec.template.spec.containers[0].resources.limits['cpu'])\n",
    "                        if not has_pod and job.status.active is None and job.status.terminating is None and job.status.succeeded is None and job.status.completion_time is None and job.status.ready == 0 and job.status.conditions is None :\n",
    "                            pending_cores = pending_cores + job_cores\n",
    "                        if job.status.failed is not None:\n",
    "                            preempted_cores += job_cores\n",
    "\n",
    "                    self.exp_data[namespace+'_pending'].append(pending_cores)\n",
    "                    self.exp_data[namespace+'_running'].append(running_cores)\n",
    "                    self.exp_data[namespace+'_completed'].append(completed_cores)\n",
    "                    self.exp_data[namespace+'_preempted'].append(preempted_cores)\n",
    "\n",
    "\n",
    "                # check to see if there are still any running or pending jobs\n",
    "                total_pending, total_running, total_completed, total_preempted = self.get_totals(self.namespaces)\n",
    "                print(\"time\", round(time.time()), \"timestamp\", _time, \"pending\", total_pending, \"running\", total_running, \"completed\", total_completed, \"preempted\", total_preempted)\n",
    "                #if total_pending == 0 and total_running == 0 and total_completed > 0:\n",
    "                if total_completed >= completed_target:\n",
    "                    finished = True\n",
    "                #timestamp += 1\n",
    "                time.sleep(1)\n",
    "            print(\"all done!\")\n",
    "            return self.exp_data\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    def graph(self):\n",
    "\n",
    "        exp_full_dataframe = pd.DataFrame(self.exp_data)\n",
    "        exp_full_dataframe.to_csv(self.experiment_name + \"-run\" + self.experiment_number + \"-rawdata.csv\", index=False)\n",
    "\n",
    "        exp_data_copy = exp_data.copy()\n",
    "        # for graph, remove completed pods\n",
    "        for namespace in self.namespaces:\n",
    "            self.exp_data.pop(namespace+'_completed')\n",
    "\n",
    "        exp_dataframe = pd.DataFrame(self.exp_data)\n",
    "\n",
    "        color = [\"blue\", \"blue\", \"blue\", \"green\", \"green\", \"green\", \"red\", \"red\", \"red\", \"orange\", \"orange\", \"orange\"]\n",
    "        style = [\"--\",   \"-\",    \".-\",   \"--\",    \"-\",     \".-\",    \"--\",  \"-\",   \".-\",  \"--\",     \"-\",      \".-\"]\n",
    "\n",
    "        plot = exp_dataframe.plot(x=\"timestamp\", figsize=(20,10), color=color, style=style, fontsize=\"14\", lw=2)\n",
    "        plot.set_xlabel(\"Run time (seconds)\", fontsize=16)\n",
    "        plot.set_ylabel(\"Number of Cores\", fontsize=16)\n",
    "        #plot.legend(fontsize=14, bbox_to_anchor=(1.19, 0.6), loc=\"center right\")\n",
    "        plot.legend(fontsize=14)\n",
    "\n",
    "        figure = plot.figure\n",
    "        #figure.tight_layout()\n",
    "        figure.savefig(self.experiment_name + \"-run\" + self.experiment_number + \"-graph-preemption.png\")\n",
    "\n",
    "        # for graph, remove completed pods\n",
    "        for namespace in self.namespaces:\n",
    "            exp_data.pop(namespace+'_preempted')\n",
    "\n",
    "        exp_dataframe = pd.DataFrame(exp_data)\n",
    "\n",
    "        color = [\"blue\", \"blue\", \"green\", \"green\", \"red\", \"red\", \"orange\", \"orange\"]\n",
    "        style = [\"--\",   \"-\",    \"--\",    \"-\",     \"--\",  \"-\",   \"--\",     \"-\"]\n",
    "\n",
    "        plot = exp_dataframe.plot(x=\"timestamp\", figsize=(20,10), color=color, style=style, fontsize=\"14\", lw=2)\n",
    "        plot.set_xlabel(\"Run time (seconds)\", fontsize=16)\n",
    "        plot.set_ylabel(\"Number of Cores\", fontsize=16)\n",
    "        plot.legend(fontsize=14)\n",
    "        #plot.legend(fontsize=14, bbox_to_anchor=(1.19, 0.6), loc=\"center right\")\n",
    "\n",
    "        figure = plot.figure\n",
    "        figure.savefig(self.experiment_name + \"-run\" + self.experiment_number + \"-graph.png\")\n",
    "        \n",
    "    def save_results(self):\n",
    "        all_pods = core_api.list_pod_for_all_namespaces()\n",
    "        all_jobs = batch_api.list_job_for_all_namespaces()\n",
    "        # filter for pods with \"tenant\" in the name\n",
    "        all_tenant_pods = [ pod for pod in all_pods.items if \"tenant\" in pod.metadata.name]\n",
    "        all_tenant_jobs = [ job for job in all_jobs.items if \"tenant\" in job.metadata.name]   \n",
    "\n",
    "        # set up output csv for dependent variables\n",
    "        output_csv = self.experiment_name + \"-run\" + self.experiment_number + \"-depvars.csv\"\n",
    "        output_fields = [\"experiment\", \"run\", \"tenant\", \"total cores\", \"total queue time\", \"avg queue time\", \"total job run time\", \"total queue + job run time\", \"workflow run time (makespan)\"]\n",
    "        output_rows = []\n",
    "\n",
    "        for namespace in self.namespaces:\n",
    "            tenant_pods = [ pod for pod in all_tenant_pods if namespace in pod.metadata.name]\n",
    "            tenant_jobs = [ job for job in all_tenant_jobs if namespace in job.metadata.name]\n",
    "\n",
    "            total_cores = 0\n",
    "            total_queue_time = 0\n",
    "            total_run_time = 0\n",
    "            total_time = 0\n",
    "\n",
    "            # start/end used to calculate makespan\n",
    "            start = None\n",
    "            end = None\n",
    "            makespan = 0\n",
    "            for pod in tenant_pods:\n",
    "                cores = int(pod.spec.containers[0].resources.limits['cpu'])\n",
    "                total_cores += cores\n",
    "                pod_schedule_time = pod.metadata.creation_timestamp\n",
    "                job_name = pod.metadata.name[:-6]\n",
    "                for job in tenant_jobs:\n",
    "                    if job.metadata.name == job_name:\n",
    "                        schedule_time = job.metadata.creation_timestamp\n",
    "                #pod_start_time = pod.status.start_time\n",
    "                pod_start_time = pod.status.container_statuses[0].state.terminated.started_at\n",
    "                pod_end_time = pod.status.container_statuses[0].state.terminated.finished_at\n",
    "                pod_queue_time = pod_start_time - schedule_time\n",
    "                pod_run_time = pod_end_time - pod_start_time\n",
    "                pod_total_time = pod_end_time - schedule_time\n",
    "                total_queue_time = total_queue_time + int(pod_queue_time.total_seconds())\n",
    "                total_run_time = total_run_time + int(pod_run_time.total_seconds())\n",
    "                total_time = total_time + int(pod_total_time.total_seconds())\n",
    "                # calculate makespan\n",
    "                if not start or schedule_time < start:\n",
    "                    start = schedule_time\n",
    "                if not end or pod_end_time > end:\n",
    "                    end = pod_end_time\n",
    "                #print(pod.metadata.name, pod_start_time, int(pod_queue_time.total_seconds()))\n",
    "            average_queue_time = round(total_queue_time / len(tenant_pods))\n",
    "            print(namespace, \"Total queue time:\", total_queue_time)\n",
    "            print(namespace, \"Average queue time:\", average_queue_time)\n",
    "            print(namespace, \"Total run time for all jobs:\", total_run_time)\n",
    "            print(namespace, \"Total queue + run time for all jobs:\", total_time)\n",
    "            makespan = round((end - start).total_seconds())\n",
    "            print(namespace, \"Total workflow run time (makespan):\", makespan)\n",
    "            output_rows.append([experiment_name, experiment_number, namespace, total_cores, total_queue_time, average_queue_time, total_run_time, total_time, makespan])\n",
    "\n",
    "        with open(output_csv, 'w') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            csvwriter.writerow(output_fields)\n",
    "            csvwriter.writerows(output_rows)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b32956-ad19-4f0c-8d21-8e798e07e9b6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "k8s = Kubernetes()\n",
    "\n",
    "experiment_name = \"E5\"\n",
    "experiment_number = \"8\"\n",
    "\n",
    "#namespaces = [\"tenant1\", \"tenant2\"]\n",
    "#namespaces = [\"tenant1\", \"tenant2\", \"tenant3\"]\n",
    "namespaces = [\"tenant1\", \"tenant2\", \"tenant3\", \"backfill\"]\n",
    "\n",
    "#scheduler_name = \"scheduler-plugins-scheduler\"\n",
    "#scheduler_name = \"nos-scheduler\"\n",
    "scheduler_name = \"yunikorn\"\n",
    "\n",
    "\n",
    "# [start_time, cpu_limit, mem_limit, num_jobs, sleep_time]\n",
    "# cms\n",
    "bursts_tenant1 = [\n",
    "    [30,  \"4\", \"8G\", 96, \"600\"],\n",
    "    [90, \"4\", \"8G\", 96, \"600\"]\n",
    "]\n",
    "\n",
    "# was using 96 to match tenant1, changed to 32 for 2x quota\n",
    "bursts_tenant2 = [\n",
    "    [60,  \"4\", \"8G\", 32, \"300\"],\n",
    "    [120, \"4\", \"8G\", 32, \"300\"]\n",
    "]\n",
    "\n",
    "# ds\n",
    "bursts_tenant3 = [\n",
    "    [230, \"2\", \"4G\", 48, \"150\"],\n",
    "    [260, \"2\", \"4G\", 96, \"150\"]\n",
    "\n",
    "]\n",
    "\n",
    "# backfill\n",
    "bursts_tenant4 = [\n",
    "    [1, \"8\", \"16G\", 48, \"900\"],\n",
    "]\n",
    "\n",
    "# format of parameters list of lists\n",
    "# params = [\n",
    "#     [namespace1, cpu_limit, mem_limit, num_jobs, sleep_time, submission_interval],\n",
    "#     [namespace2, cpu_limit, mem_limit, num_jobs, sleep_time, submission_interval],\n",
    "# ]\n",
    "\n",
    "\n",
    "# use \"0\" for cpu_limit to not submit jobs, only bursts\n",
    "params = [\n",
    "    [\"tenant1\", \"0\", \"4G\", 180, \"60\", bursts_tenant1, 1],\n",
    "    [\"tenant2\", \"0\", \"4G\", 180, \"60\", bursts_tenant2, 1],\n",
    "    [\"tenant3\", \"2\", \"4G\", 64, \"60\", bursts_tenant3, 5],\n",
    "    [\"backfill\", \"0\", \"4G\", 180, \"60\", bursts_tenant4, 1], \n",
    "\n",
    "]\n",
    "#[\"tenant2\", \"1\", \"2G\", 750, \"60\", 1.5],\n",
    "#[\"tenant3\", \"1\", \"2G\", 500, \"60\", 2]\n",
    "\n",
    "\n",
    "exp = Experiment(experiment_name, experiment_number, namespaces, scheduler_name, params)\n",
    "completed_target = exp.calculate_total_completed()\n",
    "print(completed_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066a13f-8155-49b8-bf36-bea8fa447e91",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.cleanup_all_namespaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a49fc-16f7-4d8e-bd4f-3bfd0b650be9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc73c8-22f1-49fa-803d-60fd11d1b6bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_data = {}\n",
    "exp_data = exp.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c9eb9-e360-485c-be78-e7dc414d9af1",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### Dictionary format used to store experiment data\n",
    "\n",
    "Assuming `namespaces = [\"tenant1\", \"tenant2\", \"tenant3\"]` the dictionary would be created as follows:\n",
    "```\n",
    "data = {\n",
    "    'timestamp':[1,2,3,4,5],\n",
    "    'tenant1_pending':[3,4,3,4,5],\n",
    "    'tenant1_running':[5,6,5,6,5],\n",
    "    'tenant1_completed':[7,6,7,8,7],\n",
    "    'tenant2_pending':[1,1,1,1,1],\n",
    "    'tenant2_running':[2,2,2,2,2],\n",
    "    'tenant2_completed':[3,3,3,3,3],\n",
    "    'tenant3_pending':[2,3,2,3,2],\n",
    "    'tenant3_running':[3,4,3,4,3],\n",
    "    'tenant3_completed':[5,5,5,5,5],\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb617bc-af5e-442a-b505-e04b056527f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b019b-b6ad-4d84-bef2-15d58fd840e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 196, 216 (pending)\n",
    "# 104, 128 (pending)\n",
    "# 64, 88 (pending)\n",
    "# 40, 64 (pending)\n",
    "# 32, 56 (pending)\n",
    "# 32, 56 (pending)\n",
    "# 196, 216 (pending)\n",
    "# 112, 136 (pending)\n",
    "# 64, 88 (pending)\n",
    "# 48, 72 (pending)\n",
    "# 32, 56 (pending)\n",
    "# 24, 32 (pending)\n",
    "# 24, 32 (pending)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a75dd-a8a9-4d08-bc0f-24cd3c4ce531",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94111b48-dddb-429d-a3cb-a7161d5fd37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for namespace in namespaces:\n",
    "#    print(exp_data[namespace + '_running'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c770f7f-2e4b-4412-8428-a76cc9ae9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69e611-5a34-4a80-a5d0-e0f34fd52e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
